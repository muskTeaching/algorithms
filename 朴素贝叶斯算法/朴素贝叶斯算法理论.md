###朴素贝叶斯的基本理论

之前我们学习了逻辑回归算法和梯度下降算法，我们知道逻辑回归算法本身适合于二分类的问题。在涉及多分类的问题时，需要将算法拓展。那么是否存在本身就适合多分类的算法呢？有的，朴素贝叶斯算法就是其中一个。

####1、贝叶斯理论
#####1)朴素贝叶斯的核心
贝叶斯理论的核心就是一个公式：
$$P(B|A)P(A)=P(AB)=P(A|B)P(B)$$
该公式的含义为:事件A发生的条件下事件B发生的概率等于事件A和B同时发生的概率除以事件A发生的概率。

举个例子：事件A=掷骰子的点数为偶数，B=掷骰子的点数为2，那么:$P(A)=\frac{1}{2}$,$P(B)=\frac{1}{6}$那么事件：掷骰子的点数为偶数的条件下点数为2的概率为$\frac{1}{3}$,因为为偶数的点数只有3种可能：{2，4，6}，那么为2的概率即为$P(B|A)=\frac{1}{3}$
而点数为偶数且点数为2的事件概率为:$P(AB)=\frac{1}{6}$
所以：$P(B|A)=P(AB)/P(A)=\frac{1}{6}/\frac{1}{2}=\frac{1}{3}$
在公式的右侧，则有：$P(A|B)$表示事件B发生的条件下A发生的概率，即为点数为2的情况下点数为偶数的概率，很显然这是必然事件，概率为1；则$P(A|B)P(B)=\frac{1}{6}=P(AB)=P(B|A)P(A)$


#####2）朴素贝叶斯的核心思想
将上面的公式换为高维的变量，就变成了：
$$P(Y|X)=\frac{P(X|Y)P(Y)}{P(X)}$$
其中，$Y$为类别，也是我们的目标变量，$X$为变量数据。我们知道：$P(X|Y)P(Y)=P(XY)$,其中$P(XY)$是$X$和$Y$的联合分布。我们知道数据都服从一定的分布规律，$P(XY)$是事件$X Y$同时发生的概率，$P(X|Y)$则是先验概率，即已知$Y$的条件下，$X$发生的概率。

我们经常研究的对象$X$，是包含很多属性的。比如研究一个人是否会给优酷视频充会员，冲会员的概率有多少，这就是一个很典型的二分类问题。那么我们就需要研究这个人本身的一些属性，比如年龄、性别、收入、学历、是否喜欢某类节目等。

因此对朴素贝叶斯算法的完整体系就是：对训练数据$T={(x_1,y_1),......，(x_N,y_N)}$,其中$x_i=(x_i^{(1)},x_i^{(2)},......,x_i^{(n)})$,$x_i^{(j)}$是第$i$个样本的第$j$个特征，$x_j \in \{a_j{_1},......,a_jS{_j}\}$,$a_j{_l}$是第$j$个特征可能取的第$l$个值。$j=1,2,......,n;l=1,2,......,S_j;y_i \in\{c1,c2,......,c_K\}$
输出：实例x的类别

第一步是计算先验概率及条件概率：
$$P(Y=c_k)=\frac{\sum_{i=1}^{n}I(y_i=c_k)}{N},k=1,2,3,......,K$$
$$P(X^{(j)}=a_{jl}|Y=c_k)=\frac{\sum_{i=1}^{n}I(x_i^{(j)}=a_{jl},y_i=c_k)}{\sum_{i=1}^{N}I(y_i=c_k)}$$
$$j=1,2,......,n;l=1,2,......,S_j;y_i \in\{c1,c2,......,c_K\}$$

第二步，对于给定的实例$x=(x^{(1)},......,x^{(n)})^T$,计算：
$$P(Y=c_k)\prod_{j=1}^{n}P(X^{(j)}=x^{(j)}|Y=c_k),k=1,2,......,K$$
即计算实例$x$在每个类别的后验概率的大小。

第三步，确地$x$的类别，即：
$$y=\underset{c_j}{argmax} P(Y=c_k)\prod_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)$$
在第二步我们计算出了实例$x$在它的属性取值条件下在每个类别下的后验概率，于是第三步就是从上述所有的后验概率中取一个概率最大的类别作为实例的最终类别归属。
